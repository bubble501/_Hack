## 简介

本文介绍的是以为中国的IT资深人士写的一个简单的数据库，没有我们使用的数据库那么强大，但是值得大家借鉴。可以用在特定环境中，更加灵活方便。数据库的名字叫WawaDB，是用python实现的。由此可见python是灰常强大啊！

记录数据的需求是这样的：

* 只追加，不修改，写入按时间顺序写入
* 大量写，少量读，查询一般查询一个时间段的数据

MongoDB的固定集合很好的满足了这个需求，但MongoDBF占用内存比较大，有点火穿蚊子，小题大作的感觉

这个练习实现的简单数据库思路是每写入1000条数据记录，就在一个索引文件里记录下当前的时间和数据库文件的偏移量。然后按时间查询数据记录时，先把索引加载到内存中，用二分法查找出时间点的偏移量，再打开数据库文件seek到指定位置，这样就能很快定位用户需要的数据并读取，而不需要遍历整个数据库文件

对于本次练习的程序，执行`python WawaDB.py`，然后即可看到data目录下生成了数据库文件和索引文件，当然可以试着对这个简单的数据库增加更全面的功能

## 数据库全面介绍

### 索引

只对日志记录的时间做索引，简介中大概说了下索引的实现，二分法查找肯定没有B-Tree效率高，但一般情况下也差不到一个数量级，而且实现更为简单

因为是稀疏索引(正如简介中说的，每写入1000条记录才在索引文件中记录下当前的时间和数据库文件的偏移量)，并不是在索引文件中记录下数据库文件中每条记录在数据库文件中的偏移量，所以读取数据时要往前多读一些数据，防止漏读，等读到真正所需的数据时再真正给用户返回数据

如下所示，假如索引以10为间隔记录，用户要读取25到43的数据记录：

```
索引：0      10       20       30       40       50
记录：0....9 10....19 20....29 30....39 40....49 50
```

用二分法找到25，找到的是30所在的点，所以要往前倒一些，从20(30的前一个刻度)开始读取日志，21、22、23、24读取到后因为都比25小，所以丢掉，读取25、26、27...返回给用户；读到40(50的前一个刻度)后就要判断当前数据是否大于43了，如果大于43(返回全开区间的数据)，就要停止读了

>整体下来我们只操作了大文件的很少一部分就得到了用户想要的数据！

### 缓冲区

为了减少写入记录时大量的磁盘写，索引在append记录时，把buffer设置成10k，系统默认应该是4k

同理，为了提高读取记录的效率，读取的buffer也设置位10k，也需要根据你的数据记录的大小适当调整

索引的读写设置成了行buffer，每满一行都要flush到磁盘上，防止读到不完整的索引行（其实实践证明，设置了行buffer，还是能读到半拉的行）

### 查询

并不是支持SQL查询。现在查询是直接传入一个lambda表达式，系统遍历指定时间范围内的数据行时，满足用户的lambda条件才会返回给用户

当然这样会多读取很多用户不需要的数据，而且每行都要进行lambda表达式的运算，不过没有办法，简单就是美啊

以前是把一个需要查询的条件和记录时间、记录文件偏移量都记录在索引中，这样从索引里查找出符合条件的偏移量，然后每条数据都从数据库文件中seek一次、read一次。这样的好处只有一个，就是读取的数据量少了，但缺点有两个：索引文件特别大，不方便加载到内存中；每次读取都要先seek，貌似缓冲区用不上，特别慢，比连续读一个段的数据，并用lambda过滤慢4、5倍

### 写入

前面说过，只append，不修改数据，而且每条记录最前面是时间戳

### 多线程

查询数据，可以多线程同时查询，每次查询都会打开一个新的数据库文件的描述符，所以并行的读取不会冲突

写入的话，虽然只是append操作，但是并不是线程安全的，所以建议用一个队列，一个专门的线程来写入

### 锁

没有任何锁

### 排序

默认查询出来的数据是按时间正序排列，如果需要其他排序，可以在取到内存后用python的sorted函数排序，想怎么排就怎么排

## 补充知识介绍:yield

在介绍yield前有必要先说明下Python中的迭代器(iterator)和生成器(constructor)。

### 迭代器(iterator)

在Python中，for循环可以用于Python中的任何类型，包括列表、元祖等等，实际上，for循环可用于任何“可迭代对象”，这其实就是迭代器

迭代器是一个实现了迭代器协议的对象，Python中的迭代器协议就是有next方法的对象会前进到下一结果，而在一系列结果的末尾是，则会引发StopIteration。任何这类的对象在Python中都可以用for循环或其他遍历工具迭代，迭代工具内部会在每次迭代时调用next方法，并且捕捉StopIteration异常来确定何时离开。

使用迭代器一个显而易见的好处就是：每次只从对象中读取一条数据，不会造成内存的过大开销。

比如要逐行读取一个文件的内容，利用readlines()方法，我们可以这么写：

```
for line in open("test.txt").readlines():
    print line
```

这样虽然可以工作，但不是最好的方法。因为他实际上是把文件一次加载到内存中，然后逐行打印。当文件很大时，这个方法的内存开销就很大了。

利用file的迭代器，我们可以这样写：

```
for line in open("test.txt"):   #use file iterators
    print line
```

这是最简单也是运行速度最快的写法，他并没显式的读取文件，而是利用迭代器每次读取下一行。

### 生成器(constructor)

生成器函数在Python中与迭代器协议的概念联系在一起。简而言之，包含yield语句的函数会被特地编译成生成器。当函数被调用时，他们返回一个生成器对象，这个对象支持迭代器接口。函数也许会有个return语句，但它的作用是用来yield产生值的。

不像一般的函数会生成值后退出，生成器函数在生成值后会自动挂起并暂停他们的执行和状态，他的本地变量将保存状态信息，这些信息在函数恢复时将再度有效

```
>>> def g(n):
...     for i in range(n):
...             yield i **2
...
>>> for i in g(5):
...     print i,":",
...
0 : 1 : 4 : 9 : 16 :
```

要了解他的运行原理，我们来用next方法看看：

```
>>> t = g(5)
>>> t.next()
0
>>> t.next()
1
>>> t.next()
4
>>> t.next()
9
>>> t.next()
16
>>> t.next()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration
```

在运行完5次next之后，生成器抛出了一个StopIteration异常，迭代终止。

再来看一个yield的例子，用生成器生成一个Fibonacci数列：

```
def fab(max):
    a,b = 0,1
    while a < max:
        yield a
        a, b = b, a+b
 
>>> for i in fab(20):
...     print i,",",
...
0 , 1 , 1 , 2 , 3 , 5 , 8 , 13 ,
```

看到这里应该就能理解生成器那个很抽象的概念了吧~~
